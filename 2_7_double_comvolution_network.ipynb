{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8cNl2QA_Rnv5"
   },
   "source": [
    "# 準備"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3Ub7RYdeY6pK"
   },
   "source": [
    "## sys.pathの設定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oql7L19rEsWi"
   },
   "source": [
    "以下では，Googleドライブのマイドライブ直下にDNN_codeフォルダを置くことを仮定しています．必要に応じて，パスを変更してください．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Ic2JzkvFX59"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../common')\n",
    "sys.path.append('../data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zJaxY5vv92Ne"
   },
   "source": [
    "# double_comvolution_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5BH9xs6o92Ng"
   },
   "outputs": [],
   "source": [
    "#import pickle\n",
    "import numpy as np\n",
    "import layers\n",
    "from collections import OrderedDict\n",
    "from mnist import load_mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import optimizer\n",
    "\n",
    "class DoubleConvNet:\n",
    "    # conv - relu - pool - conv - relu - pool - affine - relu - affine - softmax\n",
    "    def __init__(self, input_dim=(1, 28, 28),\n",
    "                 conv_param_1={'filter_num':10, 'filter_size':7, 'pad':1, 'stride':1},\n",
    "                 conv_param_2={'filter_num':20, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                 hidden_size=100, output_size=10, weight_init_std=0.01):\n",
    "        conv_output_size_1 = (input_dim[1] - conv_param_1['filter_size'] + 2 * conv_param_1['pad']) / conv_param_1['stride'] + 1\n",
    "        #conv_output_size_2 = (conv_output_size_1 / 2 - conv_param_2['filter_size'] + 2 * conv_param_2['pad']) / conv_param_2['stride'] + 1        \n",
    "        conv_output_size_2 = (conv_output_size_1 - conv_param_2['filter_size'] + 2 * conv_param_2['pad']) / conv_param_2['stride'] + 1  \n",
    "        pool_output_size = int(conv_param_2['filter_num'] * (conv_output_size_2 / 2) * (conv_output_size_2 / 2))        \n",
    "        # 重みの初期化\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(conv_param_1['filter_num'], input_dim[0], conv_param_1['filter_size'], conv_param_1['filter_size'])\n",
    "        self.params['b1'] = np.zeros(conv_param_1['filter_num'])\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(conv_param_2['filter_num'], conv_param_1['filter_num'], conv_param_2['filter_size'], conv_param_2['filter_size'])\n",
    "        self.params['b2'] = np.zeros(conv_param_2['filter_num'])\n",
    "        self.params['W3'] = weight_init_std * np.random.randn(pool_output_size, hidden_size)\n",
    "        self.params['b3'] = np.zeros(hidden_size)\n",
    "        self.params['W4'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b4'] = np.zeros(output_size)\n",
    "        # レイヤの生成\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Conv1'] = layers.Convolution(self.params['W1'], self.params['b1'], conv_param_1['stride'], conv_param_1['pad'])\n",
    "        self.layers['Relu1'] = layers.Relu()\n",
    "        #self.layers['Pool1'] = layers.Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "        self.layers['Conv2'] = layers.Convolution(self.params['W2'], self.params['b2'], conv_param_2['stride'], conv_param_2['pad'])\n",
    "        self.layers['Relu2'] = layers.Relu()\n",
    "        self.layers['Pool2'] = layers.Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "        self.layers['Affine1'] = layers.Affine(self.params['W3'], self.params['b3'])\n",
    "        self.layers['Relu3'] = layers.Relu()\n",
    "        self.layers['Affine2'] = layers.Affine(self.params['W4'], self.params['b4'])\n",
    "        self.last_layer = layers.SoftmaxWithLoss()\n",
    "\n",
    "    def predict(self, x):\n",
    "        for key in self.layers.keys():\n",
    "            x = self.layers[key].forward(x)\n",
    "        return x\n",
    "        \n",
    "    def loss(self, x, d):\n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y, d)\n",
    "\n",
    "    def accuracy(self, x, d, batch_size=100):\n",
    "        if d.ndim != 1 : d = np.argmax(d, axis=1)\n",
    "        \n",
    "        acc = 0.0\n",
    "        \n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            td = d[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == td) \n",
    "        \n",
    "        return acc / x.shape[0]\n",
    "\n",
    "    def gradient(self, x, d):\n",
    "        # forward\n",
    "        self.loss(x, d)\n",
    "        \n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "        layers = list(self.layers.values())\n",
    "        \n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 設定\n",
    "        grad = {}\n",
    "        grad['W1'], grad['b1'] = self.layers['Conv1'].dW, self.layers['Conv1'].db\n",
    "        grad['W2'], grad['b2'] = self.layers['Conv2'].dW, self.layers['Conv2'].db        \n",
    "        grad['W3'], grad['b3'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "        grad['W4'], grad['b4'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 652
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 60693,
     "status": "ok",
     "timestamp": 1567226464420,
     "user": {
      "displayName": "Fumitaro GOTO",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAubrhEDJVP-rnoha-qvz9ByB1M60D47F3l4Mpr=s64",
      "userId": "04811870787810218771"
     },
     "user_tz": -540
    },
    "id": "rPtHykqj92Nk",
    "outputId": "9343ccf1-f0fd-466f-b078-874956f6c128"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "データ読み込み完了\n",
      "Generation: 10. 正答率(トレーニング) = 0.4228\n",
      "                : 10. 正答率(テスト) = 0.464\n",
      "Generation: 20. 正答率(トレーニング) = 0.4584\n",
      "                : 20. 正答率(テスト) = 0.479\n",
      "Generation: 30. 正答率(トレーニング) = 0.6596\n",
      "                : 30. 正答率(テスト) = 0.634\n",
      "Generation: 40. 正答率(トレーニング) = 0.723\n",
      "                : 40. 正答率(テスト) = 0.709\n",
      "Generation: 50. 正答率(トレーニング) = 0.7696\n",
      "                : 50. 正答率(テスト) = 0.744\n"
     ]
    }
   ],
   "source": [
    "# データの読み込み\n",
    "(x_train, d_train), (x_test, d_test) = load_mnist(flatten=False)\n",
    "\n",
    "print(\"データ読み込み完了\")\n",
    "# 処理に時間のかかる場合はデータを削減 \n",
    "x_train, d_train = x_train[:5000], d_train[:5000]\n",
    "x_test, d_test = x_test[:1000], d_test[:1000]\n",
    "\n",
    "\n",
    "network = DoubleConvNet(input_dim=(1,28,28), \n",
    "                          conv_param_1={'filter_num':10, 'filter_size':7, 'pad':1, 'stride':1},\n",
    "                          conv_param_2={'filter_num':20, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                          hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "\n",
    "optimizer = optimizer.Adam()\n",
    "\n",
    "# 時間がかかるため100に設定\n",
    "iters_num = 100\n",
    "# iters_num = 1000\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "\n",
    "train_loss_list = []\n",
    "accuracies_train = []\n",
    "accuracies_test = []\n",
    "\n",
    "plot_interval=10\n",
    "\n",
    "\n",
    "\n",
    "for i in range(iters_num):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    d_batch = d_train[batch_mask]\n",
    "    \n",
    "    grad = network.gradient(x_batch, d_batch)\n",
    "    optimizer.update(network.params, grad)\n",
    "    loss = network.loss(x_batch, d_batch)\n",
    "    train_loss_list.append(loss)\n",
    "\n",
    "    if (i+1) % plot_interval == 0:\n",
    "        accr_train = network.accuracy(x_train, d_train)\n",
    "        accr_test = network.accuracy(x_test, d_test)\n",
    "        accuracies_train.append(accr_train)\n",
    "        accuracies_test.append(accr_test)\n",
    "        \n",
    "        print('Generation: ' + str(i+1) + '. 正答率(トレーニング) = ' + str(accr_train))\n",
    "        print('                : ' + str(i+1) + '. 正答率(テスト) = ' + str(accr_test))               \n",
    "\n",
    "lists = range(0, iters_num, plot_interval)\n",
    "plt.plot(lists, accuracies_train, label=\"training set\")\n",
    "plt.plot(lists, accuracies_test,  label=\"test set\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.title(\"accuracy\")\n",
    "plt.xlabel(\"count\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "# グラフの表示\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ID8VTrG292No"
   },
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "## [try] DoubleConvNetをアレンジしよう\n",
    "pooling層を一つ減らしたものに変えてみよう<br>\n",
    "conv - relu - conv - relu - pool - affine - relu - affine - softmax\n",
    "\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "2_7_double_comvolution_network.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
